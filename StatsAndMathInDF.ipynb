{"nbformat_minor": 1, "cells": [{"source": "## Python Statistics & Mathematical Functions\nCode in Python 3 in statistics and mathematical functions to work with data\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "from pyspark.sql.functions import rand, randn\n# create a dataframe with one int column and 10 rows.\ndf = sqlContext.range(0,10)\ndf.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1481557039118_0006</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn0-mospar.twmenjeggjdevpe115h0vi400f.cx.internal.cloudapp.net:8088/proxy/application_1481557039118_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.5:30060/node/containerlogs/container_1481557039118_0006_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n|  5|\n|  6|\n|  7|\n|  8|\n|  9|\n+---+"}], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "# generate two other columns\ndf.select(\"id\", rand(seed=10).alias(\"uniform\"),randn(seed=27).alias(\"normal\")).show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+-------------------+--------------------+\n| id|            uniform|              normal|\n+---+-------------------+--------------------+\n|  0|0.41371264720975787|  0.5888539012978773|\n|  1| 0.7311719281896606|  0.8645537008427937|\n|  2| 0.1982919638208397| 0.06157382353970104|\n|  3|0.12714181165849525|  0.3623040918178586|\n|  4| 0.7604318153406678|-0.49575204523675975|\n|  5|0.12030715258495939|  1.0854146699817222|\n|  6|0.12131363910425985| -0.5284523629183004|\n|  7|0.44292918521277047| -0.4798519469521663|\n|  8| 0.8898784253886249| -0.8820294772950535|\n|  9|0.03650707717266999| -2.1591956435415334|\n+---+-------------------+--------------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "df = sqlContext.range(0,10).withColumn('uniform', rand(seed=10)).withColumn('normal', randn(seed=27))", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 12, "cell_type": "code", "source": "df.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+-------------------+--------------------+\n| id|            uniform|              normal|\n+---+-------------------+--------------------+\n|  0|0.41371264720975787|  0.5888539012978773|\n|  1| 0.7311719281896606|  0.8645537008427937|\n|  2| 0.1982919638208397| 0.06157382353970104|\n|  3|0.12714181165849525|  0.3623040918178586|\n|  4| 0.7604318153406678|-0.49575204523675975|\n|  5|0.12030715258495939|  1.0854146699817222|\n|  6|0.12131363910425985| -0.5284523629183004|\n|  7|0.44292918521277047| -0.4798519469521663|\n|  8| 0.8898784253886249| -0.8820294772950535|\n|  9|0.03650707717266999| -2.1591956435415334|\n+---+-------------------+--------------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "df.describe().show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+------------------+-------------------+--------------------+\n|summary|                id|            uniform|              normal|\n+-------+------------------+-------------------+--------------------+\n|  count|                10|                 10|                  10|\n|   mean|               4.5| 0.3841685645682706|-0.15825812884638607|\n| stddev|3.0276503540974917|0.31309395532409323|   0.963345903544872|\n|    min|                 0|0.03650707717266999| -2.1591956435415334|\n|    max|                 9| 0.8898784253886249|  1.0854146699817222|\n+-------+------------------+-------------------+--------------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 15, "cell_type": "code", "source": "from pyspark.sql.functions import mean, min, max\ndf.select([mean('uniform'), min('uniform'), max('uniform')]).show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------------+-------------------+------------------+\n|      avg(uniform)|       min(uniform)|      max(uniform)|\n+------------------+-------------------+------------------+\n|0.3841685645682706|0.03650707717266999|0.8898784253886249|\n+------------------+-------------------+------------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 20, "cell_type": "code", "source": "from pyspark.sql.functions import rand\ndf = sqlContext.range(0,10).withColumn('rand1', rand(seed=1)).withColumn('rand2', rand(seed=27))\ndf.stat.cov('rand1','rand2')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "-0.030127356842433402"}], "metadata": {"collapsed": false}}, {"execution_count": 21, "cell_type": "code", "source": "df.stat.cov('id','id')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "9.166666666666666"}], "metadata": {"collapsed": false}}, {"execution_count": 22, "cell_type": "code", "source": "df.stat.corr('rand1', 'rand2')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "-0.35334465640136176"}], "metadata": {"collapsed": false}}, {"execution_count": 23, "cell_type": "code", "source": "df.stat.corr('id','id')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1.0"}], "metadata": {"collapsed": false}}, {"execution_count": 26, "cell_type": "code", "source": "\n# create a dataframe with two columns name and item\nnames = ['Alice', 'Bob', 'Mike']\nitems = ['milk', ' bread', 'butter', 'bananas', 'oranges']\ndf = sqlContext.createDataFrame([(names[i%3],items[i%5]) for i in range(100)], ['name','item'])\ndf.show(10)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+-------+\n| name|   item|\n+-----+-------+\n|Alice|   milk|\n|  Bob|  bread|\n| Mike| butter|\n|Alice|bananas|\n|  Bob|oranges|\n| Mike|   milk|\n|Alice|  bread|\n|  Bob| butter|\n| Mike|bananas|\n|Alice|oranges|\n+-----+-------+\nonly showing top 10 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 27, "cell_type": "code", "source": "df.stat.crosstab(\"name\", \"item\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---------+------+-------+------+----+-------+\n|name_item| bread|bananas|butter|milk|oranges|\n+---------+------+-------+------+----+-------+\n|      Bob|     7|      6|     7|   6|      7|\n|     Mike|     6|      7|     7|   7|      6|\n|    Alice|     7|      7|     6|   7|      7|\n+---------+------+-------+------+----+-------+"}], "metadata": {"collapsed": false}}, {"execution_count": 30, "cell_type": "code", "source": "df= sqlContext.createDataFrame([(1,2,3) if i%2 == 0 else (i, i*2, i%4) for i in range(100)], ['a','b','c'])\ndf.show(10)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---+---+---+\n|  a|  b|  c|\n+---+---+---+\n|  1|  2|  3|\n|  1|  2|  1|\n|  1|  2|  3|\n|  3|  6|  3|\n|  1|  2|  3|\n|  5| 10|  1|\n|  1|  2|  3|\n|  7| 14|  3|\n|  1|  2|  3|\n|  9| 18|  1|\n+---+---+---+\nonly showing top 10 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 32, "cell_type": "code", "source": "freq = df.stat.freqItems(['a','b','c'], 0.4)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 33, "cell_type": "code", "source": "freq.collect()[0]", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Row(a_freqItems=[23, 1], b_freqItems=[2, 46], c_freqItems=[1, 3])"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}